{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae58262d-0bcc-4180-bedf-5fa45b7a1569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\micha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['compound'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_824\\2005011297.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0msentiment_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarket_sent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_824\\2005011297.py\u001b[0m in \u001b[0;36mmarket_sent\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# Make a new dataframe called sentiment_df that groups the average sentiment for each day\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0msentiment_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnyt_sentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0msentiment_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3812\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3813\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3815\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6068\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6070\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6072\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6129\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6130\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6132\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['compound'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# General packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import datetime as dt\n",
    "nltk.download('vader_lexicon') \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#turn off warning signs for cleaner code\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "def market_sent ():\n",
    "    today = dt.date.today()\n",
    "    current_year = (int(today.strftime(\"%Y\")) + 1)\n",
    "    start_year = today - dt.timedelta(days=365*20)\n",
    "    start_year = (int(start_year.strftime(\"%Y\")) + 1)\n",
    "    \n",
    "    # get api key\n",
    "    load_dotenv(\"nyt\")\n",
    "    api_key = os.getenv(\"NYT\")\n",
    "    url = \"https://api.nytimes.com/svc/archive/v1/{}/{}.json?api-key={}&q=economy\"\n",
    "\n",
    "    # Create an empty dataframe\n",
    "    nyt_sentiment = pd.DataFrame(columns=[\"headline\", \"date\", \"compound\"])\n",
    "\n",
    "    # Initialize the VADER sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Loop through each year and each month from 2003 to today\n",
    "    for year in range(start_year, current_year):\n",
    "        for month in range(1, 13):\n",
    "            # Format the year and month as a string\n",
    "            year_month = f\"{year}/{month:02d}\"\n",
    "\n",
    "            # Make a request to the NYT API\n",
    "            response = requests.get(url.format(year, month, api_key))\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                articles = data[\"response\"][\"docs\"]\n",
    "\n",
    "                # Loop through each article and add the headline, date, and sentiment scores to the nyt_sentiment dataframe\n",
    "                for article in articles:\n",
    "                    # Check if the article is about the economy\n",
    "                    testers = ['economy', 's&p', 'stock market', 'us economy']\n",
    "                    if any([x in article[\"snippet\"].lower() for x in testers]) or any([x in article[\"abstract\"].lower() for x in testers]) :\n",
    "                        # Get the sentiment scores for the headline and add them to the nyt_sentiment dataframe\n",
    "                        scores = analyzer.polarity_scores(article[\"headline\"][\"main\"]+\" \"+article[\"abstract\"])\n",
    "                        nyt_sentiment = nyt_sentiment.append({\n",
    "                            \"headline\": article[\"headline\"][\"main\"], \n",
    "                            \"date\": pd.to_datetime(article[\"pub_date\"]).date(), \n",
    "                            \"compound\": scores[\"compound\"]}, ignore_index=True)\n",
    "\n",
    "    # Set date as index\n",
    "    nyt_sentiment = nyt_sentiment.set_index('date')\n",
    "\n",
    "    # Make a new dataframe called sentiment_df that groups the average sentiment for each day\n",
    "    sentiment_df = nyt_sentiment.groupby(['date']).mean()[['compound']]\n",
    "    sentiment_df = sentiment_df.rename(columns={'compound': 'Sentiment'})\n",
    "    \n",
    "    return sentiment_df\n",
    "\n",
    "sentiment_df = market_sent()\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "680bbfb5-40f5-4d98-92b2-83ac02191852",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1944001599.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_824\\1944001599.py\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    url = \"https://api.nytimes.com\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# General packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import datetime as dt\n",
    "nltk.download('vader_lexicon') \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#turn off warning signs for cleaner code\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "today = dt.date.today()\n",
    "current_year = (int(today.strftime(\"%Y\")) + 1)\n",
    "start_year = today - dt.timedelta(days=365*20)\n",
    "start_year = (int(start_year.strftime(\"%Y\")) + 1)\n",
    "\n",
    "# get api key\n",
    "load_dotenv(\"nyt\")\n",
    "api_key = os.getenv(\"NYT\")\n",
    "url = \"https://api.nytimes.com\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69b985-347b-473f-800d-6af69e18dde3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
